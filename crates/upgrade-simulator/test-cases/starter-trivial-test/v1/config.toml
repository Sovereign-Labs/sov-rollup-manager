[da]
# Connection string for SQL database to have stored blocks, for example"
#  - "sqlite://demo_data/da.sqlite?mode=rwc"
#  - "sqlite::memory:"
#  - "postgresql://root:hunter2@aws.amazon.com/mock-da"
connection_string = "sqlite://rollup-state/mock_da.sqlite?mode=rwc"
# String representation of sequencer address.
# For initial full node should match genesis of sequencer-registry.
# It is going to be a DA address that blobs from this node will be associated.
sender_address = "0000000000000000000000000000000000000000000000000000000000000000"
finalization = 0
# Defines how new blocks should be produced.
[da.block_producing.periodic]
block_time_ms = 2_000

[storage]
# The path to the rollup's data directory. Paths that do not begin with `/` are interpreted as relative paths.
path = "./rollup-state/rollup-starter-data-mock"
user_commit_concurrency = 6
kernel_commit_concurrency = 2
# Disable pruning for now
# pruner_block_interval = 100_000
pruner_versions_to_keep = 100

#state_cache_size = 10000000000 # 10GB
#state_cache_size = 4294967296
# The number of 4kb buckets to allocate for the state DB
# The state DB will not exceed this size, and you'll get a warning when it fills up to 90% capacity.
#user_hashtable_buckets = 64_000_000 # 256 GB. You will need much more for production deployments
# This paramater introduces performance penalty and should be changed in production.
user_hashtable_buckets = 1_000_000
# It allows avoiding allocating 256GB at the start
user_preallocate_ht = false 

[runner]
da_polling_interval_ms = 200

[runner.http_config]
bind_host = "0.0.0.0"
bind_port = 12346
public_address = "http://127.0.0.1:12346"

[monitoring]
telegraf_address = "127.0.0.1:8094"
# Defines how many measurements a rollup node will accumulate before sending it to the Telegraf.
# It is expected from the rollup node to produce metrics all the time,
# so measurements are buffered by size and not sent by time.
# and below 67 KB, which is the maximal UDP packet size.
# It also means that if a single serialized metric is larger than this value, a UDP packet will be larger.
# The default value is 508.
# max_datagram_size = 508
# How many metrics are allowed to be in pending state, before new metrics will be dropped.
# This is a number of metrics, not serialized bytes.
# The total number of bytes to be held in memory might vary per metric + `max_datagram_size`
# max_pending_metrics = 100


[proof_manager]
aggregated_proof_block_jump = 1
prover_address = "0xA6edfca3AA985Dd3CC728BFFB700933a986aC085"
max_number_of_transitions_in_db = 100
max_number_of_transitions_in_memory = 20


[sequencer]
max_batch_size_bytes = 8388608 # 8 MiB
max_concurrent_blobs = 128
max_allowed_node_distance_behind = 10
rollup_address = "0xA6edfca3AA985Dd3CC728BFFB700933a986aC085"
blob_processing_timeout_secs = 60

[sequencer.preferred]
disable_state_root_consistency_checks = true
# Strategy for handling recovery scenarios when the sequencer is too far behind.
# "None" - Shutdown the sequencer instead of attempting recovery (default)
# "TryToSave" - Attempt to recover by flushing batches and catching up with the chain
recovery_strategy = "TryToSave"
batch_execution_time_limit_millis = 6000 # This should be adjusted depending on the DA layer's block times
# If you have one available, uncomment the line below to use a postgres database for the sequencer's soft confirmations. This gives much better performance and durability.
# [sequencer.preferred.postgres_config]
# postgres_connection_string = "postgresql://postgres:pass@localhost:5432/db" 
# node_id = "node_1"

ideal_lag_behind_finalized_slot = 1
# The sequencer optimistically pre-executes transactions across multiple worker threads.
# This warms up caches so the main transaction executor can run with ready-to-use data.
# This variable determines the number of worker threads.
num_cache_warmup_workers = 0
is_replica = false


# [sequencer.preferred.rate_limiter] # Setting related to rate limiter.
# max_nb_of_concurrent_users_in_rate_limiter = 100000 # Limit on how many concurrent users the rate limiter can handle.
# max_requests_per_second = 10000 # Limit on requests per second.
# address_custom_limits = [["0xA6edfca3AA985Dd3CC728BFFB700933a986aC085", { resources_per_bucket = 20, refill_rate = 2}]]
# ip_custom_limits = [
#                ["127.0.0.1", { resources_per_bucket = 1000, refill_rate = 1 }],  # This IP can use the resources of the entire batch.
#                ["157.180.34.249", { resources_per_bucket = 100, refill_rate = 2 }] # This IP can use 10% the resources of the entire batch.
#            ]
# [sequencer.preferred.rate_limiter.default_limits]
# resources_per_bucket = 5 # The resources allocated per user per rate-limiting bucket, defined in units of 1/1000th of a full batch. E.g. resources_per_bucket = 10 would mean each bucket allows the user to use 1% of a full batch capacity.
# refill_rate = 5 # The refill rate of buckets. E.g. if refill_rate = 5, the user's rate limiting bucket will be refilled up to five times every batch.

[sequencer.extension]
max_log_limit = 20000
